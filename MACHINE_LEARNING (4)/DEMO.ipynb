{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cacf2ca6",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eaa86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0176c4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Advertising.csv\")\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c161ebb5",
   "metadata": {},
   "source": [
    "# Train | Test Split Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e13b4f",
   "metadata": {},
   "source": [
    "1. Clean and adjust data as necessary for X and Y \n",
    "2. Split data in Train/Test for X and Y\n",
    "3. Fit/Train scaler on Training X data\n",
    "4. Scale X Test data\n",
    "5. Create Model\n",
    "6. Fit/Train Model on X Train data\n",
    "7. Evaluate the Model on X Test data\n",
    "8. Adjust parameter as necessary and repeat step 6 & 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31593518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X and Y \n",
    "X = df.drop(\"sales\", axis = 1)\n",
    "y = df[\"sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2d94f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = .3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e69f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b85d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bbd001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poor \"Alpha\" choose on purpose...\n",
    "model = Ridge(alpha = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82bd31b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b15632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93902fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa270dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.341775789034128"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a3c545",
   "metadata": {},
   "source": [
    "# Adjust the Parameters and Re-Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea5abdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7ae7489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad566cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec06799",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f455178",
   "metadata": {},
   "source": [
    "# Another Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17c650aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3190215794287514"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c311a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X and Y \n",
    "X = df.drop(\"sales\", axis = 1)\n",
    "y = df[\"sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21961093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#70% of data is training , set aside the other 30%...\n",
    "#train and test split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_other,y_train,y_other = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size = .3,\n",
    "                                                   random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0c7826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remaining 30% is split into Evaluation and Test data...\n",
    "X_eval,X_test,y_eval,y_test = train_test_split(X_other,\n",
    "                                               y_other,\n",
    "                                               test_size = .5,\n",
    "                                               random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2d72ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_eval = scaler.transform(X_eval)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b76c3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poor \"Alpha\" choose on purpose...\n",
    "model = Ridge(alpha = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7e25f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daecfd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = model.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15494810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.320101458823869"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_eval,y_eval_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c851210",
   "metadata": {},
   "source": [
    "# Adjust the Parameters and Re-Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f30f9d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e11d420f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62c793f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = model.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6bef564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3837830750569853"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_eval,y_eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c9e00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_test_pred1 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83440cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.254260083800517"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_final_test_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb776d",
   "metadata": {},
   "source": [
    "# Cross Validation with \"cross_val_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e05e2c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X and y\n",
    "X = df.drop(\"sales\",axis = 1)\n",
    "y = df[\"sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47bb37cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_other,y_train,y_other = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size = .3,\n",
    "                                                   random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b323ccf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#scale data\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_eval = scaler.transform(X_eval)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3209b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poor \"Alpha\" choose on purpose...\n",
    "model = Ridge(alpha = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39c2ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "467a63d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,\n",
    "                         X_train,\n",
    "                         y_train,\n",
    "                         scoring = \"neg_mean_squared_error\",\n",
    "                                    cv = 5)  \n",
    "                                   #cv is nothing but \"k\" vaue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d820a4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.32552967,  -4.9449624 , -11.39665242,  -7.0242106 ,\n",
       "        -8.38562723])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73ee5270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.215396464543607"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average of the MSE scores\n",
    "abs(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5363b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the model based on the matrics..\n",
    "model = Ridge(alpha =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f8cf359",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,\n",
    "                         X_train,\n",
    "                         y_train,\n",
    "                         scoring = \"neg_mean_squared_error\",\n",
    "                                    cv = 5)  \n",
    "                                   #cv is nothing but \"k\" vaue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e36d22ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.15513238, -1.58086982, -5.40455562, -2.21654481, -4.36709384])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c4733ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.344839296530695"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average of the MSE scores\n",
    "abs(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a991a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8529d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_final_pred2 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee213186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.05131347685386"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_test_final_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611baed8",
   "metadata": {},
   "source": [
    "#  Again Cross Validation with \"cross_val_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7bf0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X and y\n",
    "X = df.drop(\"sales\",axis = 1)\n",
    "y = df[\"sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76dec156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test split data\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_other,y_train,y_other = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size = .3,\n",
    "                                                   random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e146ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#scale data\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_eval = scaler.transform(X_eval)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adb6a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6199817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cba5b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model,\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        scoring = [\"neg_mean_absolute_error\",\n",
    "                              \"neg_mean_squared_error\",\n",
    "                              \"max_error\"],\n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19aeb03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0030036 , 0.00299382, 0.0019989 , 0.00199866, 0.00199914]),\n",
       " 'score_time': array([0.00299907, 0.00199747, 0.00299907, 0.0029974 , 0.00299883]),\n",
       " 'test_neg_mean_absolute_error': array([-2.31243044, -1.74653361, -2.56211701, -2.01873159, -2.27951906]),\n",
       " 'test_neg_mean_squared_error': array([ -9.32552967,  -4.9449624 , -11.39665242,  -7.0242106 ,\n",
       "         -8.38562723]),\n",
       " 'test_max_error': array([ -6.44988486,  -5.58926073, -10.33914027,  -6.61950405,\n",
       "         -7.75578515])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6cd6eff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_max_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>-2.312430</td>\n",
       "      <td>-9.325530</td>\n",
       "      <td>-6.449885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>-1.746534</td>\n",
       "      <td>-4.944962</td>\n",
       "      <td>-5.589261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>-2.562117</td>\n",
       "      <td>-11.396652</td>\n",
       "      <td>-10.339140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>-2.018732</td>\n",
       "      <td>-7.024211</td>\n",
       "      <td>-6.619504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>-2.279519</td>\n",
       "      <td>-8.385627</td>\n",
       "      <td>-7.755785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_neg_mean_absolute_error  \\\n",
       "0  0.003004    0.002999                     -2.312430   \n",
       "1  0.002994    0.001997                     -1.746534   \n",
       "2  0.001999    0.002999                     -2.562117   \n",
       "3  0.001999    0.002997                     -2.018732   \n",
       "4  0.001999    0.002999                     -2.279519   \n",
       "\n",
       "   test_neg_mean_squared_error  test_max_error  \n",
       "0                    -9.325530       -6.449885  \n",
       "1                    -4.944962       -5.589261  \n",
       "2                   -11.396652      -10.339140  \n",
       "3                    -7.024211       -6.619504  \n",
       "4                    -8.385627       -7.755785  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "160dc9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time                        0.002399\n",
       "score_time                      0.002798\n",
       "test_neg_mean_absolute_error   -2.183866\n",
       "test_neg_mean_squared_error    -8.215396\n",
       "test_max_error                 -7.350715\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c56d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat the process for \"aLpha = 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8e8891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ab15f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8d4b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(model,\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        scoring = [\"neg_mean_absolute_error\",\n",
    "                              \"neg_mean_squared_error\",\n",
    "                              \"max_error\"],\n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94b9c525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03a7f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_test_pred3 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "184875b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138.74399945380168"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_final_test_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0342d",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbca4a4",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6259297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#create X and y\n",
    "X = df.drop(\"sales\",axis = 1)\n",
    "y = df[\"sales\"]\n",
    "\n",
    "\n",
    "#train and test split data\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_other,y_train,y_other = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size = .3,\n",
    "                                                   random_state = 101)\n",
    "\n",
    "\n",
    "#scale data\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_eval = scaler.transform(X_eval)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c7929f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1230a9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ElasticNet in module sklearn.linear_model._coordinate_descent:\n",
      "\n",
      "class ElasticNet(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, sklearn.linear_model._base.LinearModel)\n",
      " |  ElasticNet(alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, normalize='deprecated', precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      " |  \n",
      " |  Linear regression with combined L1 and L2 priors as regularizer.\n",
      " |  \n",
      " |  Minimizes the objective function::\n",
      " |  \n",
      " |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      " |          + alpha * l1_ratio * ||w||_1\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      " |  \n",
      " |  If you are interested in controlling the L1 and L2 penalty\n",
      " |  separately, keep in mind that this is equivalent to::\n",
      " |  \n",
      " |          a * ||w||_1 + 0.5 * b * ||w||_2^2\n",
      " |  \n",
      " |  where::\n",
      " |  \n",
      " |          alpha = a + b and l1_ratio = a / (a + b)\n",
      " |  \n",
      " |  The parameter l1_ratio corresponds to alpha in the glmnet R package while\n",
      " |  alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n",
      " |  = 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n",
      " |  unless you supply your own sequence of alpha.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <elastic_net>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  alpha : float, default=1.0\n",
      " |      Constant that multiplies the penalty terms. Defaults to 1.0.\n",
      " |      See the notes for the exact mathematical meaning of this\n",
      " |      parameter. ``alpha = 0`` is equivalent to an ordinary least square,\n",
      " |      solved by the :class:`LinearRegression` object. For numerical\n",
      " |      reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
      " |      Given this, you should use the :class:`LinearRegression` object.\n",
      " |  \n",
      " |  l1_ratio : float, default=0.5\n",
      " |      The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
      " |      ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
      " |      is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
      " |      combination of L1 and L2.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether the intercept should be estimated or not. If ``False``, the\n",
      " |      data is assumed to be already centered.\n",
      " |  \n",
      " |  normalize : bool, default=False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      " |      on an estimator with ``normalize=False``.\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |          ``normalize`` was deprecated in version 1.0 and will be removed in\n",
      " |          1.2.\n",
      " |  \n",
      " |  precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
      " |      Whether to use a precomputed Gram matrix to speed up\n",
      " |      calculations. The Gram matrix can also be passed as argument.\n",
      " |      For sparse input this option is always ``False`` to preserve sparsity.\n",
      " |  \n",
      " |  max_iter : int, default=1000\n",
      " |      The maximum number of iterations.\n",
      " |  \n",
      " |  copy_X : bool, default=True\n",
      " |      If ``True``, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      The tolerance for the optimization: if the updates are\n",
      " |      smaller than ``tol``, the optimization code checks the\n",
      " |      dual gap for optimality and continues until it is smaller\n",
      " |      than ``tol``.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  positive : bool, default=False\n",
      " |      When set to ``True``, forces the coefficients to be positive.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      The seed of the pseudo random number generator that selects a random\n",
      " |      feature to update. Used when ``selection`` == 'random'.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  selection : {'cyclic', 'random'}, default='cyclic'\n",
      " |      If set to 'random', a random coefficient is updated every iteration\n",
      " |      rather than looping over features sequentially by default. This\n",
      " |      (setting to 'random') often leads to significantly faster convergence\n",
      " |      especially when tol is higher than 1e-4.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      " |      Parameter vector (w in the cost function formula).\n",
      " |  \n",
      " |  sparse_coef_ : sparse matrix of shape (n_features,) or             (n_targets, n_features)\n",
      " |      Sparse representation of the `coef_`.\n",
      " |  \n",
      " |  intercept_ : float or ndarray of shape (n_targets,)\n",
      " |      Independent term in decision function.\n",
      " |  \n",
      " |  n_iter_ : list of int\n",
      " |      Number of iterations run by the coordinate descent solver to reach\n",
      " |      the specified tolerance.\n",
      " |  \n",
      " |  dual_gap_ : float or ndarray of shape (n_targets,)\n",
      " |      Given param alpha, the dual gaps at the end of the optimization,\n",
      " |      same shape as each observation of y.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  ElasticNetCV : Elastic net model with best model selection by\n",
      " |      cross-validation.\n",
      " |  SGDRegressor : Implements elastic net regression with incremental training.\n",
      " |  SGDClassifier : Implements logistic regression with elastic net penalty\n",
      " |      (``SGDClassifier(loss=\"log\", penalty=\"elasticnet\")``).\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  To avoid unnecessary memory duplication the X argument of the fit method\n",
      " |  should be directly passed as a Fortran-contiguous numpy array.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.linear_model import ElasticNet\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |  \n",
      " |  >>> X, y = make_regression(n_features=2, random_state=0)\n",
      " |  >>> regr = ElasticNet(random_state=0)\n",
      " |  >>> regr.fit(X, y)\n",
      " |  ElasticNet(random_state=0)\n",
      " |  >>> print(regr.coef_)\n",
      " |  [18.83816048 64.55968825]\n",
      " |  >>> print(regr.intercept_)\n",
      " |  1.451...\n",
      " |  >>> print(regr.predict([[0, 0]]))\n",
      " |  [1.451...]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ElasticNet\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      sklearn.linear_model._base.LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, normalize='deprecated', precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True)\n",
      " |      Fit model with coordinate descent.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {ndarray, sparse matrix} of (n_samples, n_features)\n",
      " |          Data.\n",
      " |      \n",
      " |      y : {ndarray, sparse matrix} of shape (n_samples,) or             (n_samples, n_targets)\n",
      " |          Target. Will be cast to X's dtype if necessary.\n",
      " |      \n",
      " |      sample_weight : float or array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. Internally, the `sample_weight` vector will be\n",
      " |          rescaled to sum to `n_samples`.\n",
      " |      \n",
      " |          .. versionadded:: 0.23\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Coordinate descent is an algorithm that considers each column of\n",
      " |      data at a time hence it will automatically convert the X input\n",
      " |      as a Fortran-contiguous numpy array if necessary.\n",
      " |      \n",
      " |      To avoid memory re-allocation it is advised to allocate the\n",
      " |      initial data in memory directly using that format.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  path = enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)\n",
      " |      Compute elastic net path with coordinate descent.\n",
      " |      \n",
      " |      The elastic net optimization function varies for mono and multi-outputs.\n",
      " |      \n",
      " |      For mono-output tasks it is::\n",
      " |      \n",
      " |          1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      " |          + alpha * l1_ratio * ||w||_1\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      " |      \n",
      " |      For multi-output tasks it is::\n",
      " |      \n",
      " |          (1 / (2 * n_samples)) * ||Y - XW||_Fro^2\n",
      " |          + alpha * l1_ratio * ||W||_21\n",
      " |          + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      " |      \n",
      " |      Where::\n",
      " |      \n",
      " |          ||W||_21 = \\sum_i \\sqrt{\\sum_j w_{ij}^2}\n",
      " |      \n",
      " |      i.e. the sum of norm of each row.\n",
      " |      \n",
      " |      Read more in the :ref:`User Guide <elastic_net>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training data. Pass directly as Fortran-contiguous data to avoid\n",
      " |          unnecessary memory duplication. If ``y`` is mono-output then ``X``\n",
      " |          can be sparse.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix} of shape (n_samples,) or         (n_samples, n_targets)\n",
      " |          Target values.\n",
      " |      \n",
      " |      l1_ratio : float, default=0.5\n",
      " |          Number between 0 and 1 passed to elastic net (scaling between\n",
      " |          l1 and l2 penalties). ``l1_ratio=1`` corresponds to the Lasso.\n",
      " |      \n",
      " |      eps : float, default=1e-3\n",
      " |          Length of the path. ``eps=1e-3`` means that\n",
      " |          ``alpha_min / alpha_max = 1e-3``.\n",
      " |      \n",
      " |      n_alphas : int, default=100\n",
      " |          Number of alphas along the regularization path.\n",
      " |      \n",
      " |      alphas : ndarray, default=None\n",
      " |          List of alphas where to compute the models.\n",
      " |          If None alphas are set automatically.\n",
      " |      \n",
      " |      precompute : 'auto', bool or array-like of shape             (n_features, n_features), default='auto'\n",
      " |          Whether to use a precomputed Gram matrix to speed up\n",
      " |          calculations. If set to ``'auto'`` let us decide. The Gram\n",
      " |          matrix can also be passed as argument.\n",
      " |      \n",
      " |      Xy : array-like of shape (n_features,) or (n_features, n_targets),         default=None\n",
      " |          Xy = np.dot(X.T, y) that can be precomputed. It is useful\n",
      " |          only when the Gram matrix is precomputed.\n",
      " |      \n",
      " |      copy_X : bool, default=True\n",
      " |          If ``True``, X will be copied; else, it may be overwritten.\n",
      " |      \n",
      " |      coef_init : ndarray of shape (n_features, ), default=None\n",
      " |          The initial values of the coefficients.\n",
      " |      \n",
      " |      verbose : bool or int, default=False\n",
      " |          Amount of verbosity.\n",
      " |      \n",
      " |      return_n_iter : bool, default=False\n",
      " |          Whether to return the number of iterations or not.\n",
      " |      \n",
      " |      positive : bool, default=False\n",
      " |          If set to True, forces coefficients to be positive.\n",
      " |          (Only allowed when ``y.ndim == 1``).\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          If set to False, the input validation checks are skipped (including the\n",
      " |          Gram matrix when provided). It is assumed that they are handled\n",
      " |          by the caller.\n",
      " |      \n",
      " |      **params : kwargs\n",
      " |          Keyword arguments passed to the coordinate descent solver.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      alphas : ndarray of shape (n_alphas,)\n",
      " |          The alphas along the path where models are computed.\n",
      " |      \n",
      " |      coefs : ndarray of shape (n_features, n_alphas) or             (n_targets, n_features, n_alphas)\n",
      " |          Coefficients along the path.\n",
      " |      \n",
      " |      dual_gaps : ndarray of shape (n_alphas,)\n",
      " |          The dual gaps at the end of the optimization for each alpha.\n",
      " |      \n",
      " |      n_iters : list of int\n",
      " |          The number of iterations taken by the coordinate descent optimizer to\n",
      " |          reach the specified tolerance for each alpha.\n",
      " |          (Is returned when ``return_n_iter`` is set to True).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      MultiTaskElasticNet : Multi-task ElasticNet model trained with L1/L2 mixed-norm     as regularizer.\n",
      " |      MultiTaskElasticNetCV : Multi-task L1/L2 ElasticNet with built-in cross-validation.\n",
      " |      ElasticNet : Linear regression with combined L1 and L2 priors as regularizer.\n",
      " |      ElasticNetCV : Elastic Net model with iterative fitting along a regularization path.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For an example, see\n",
      " |      :ref:`examples/linear_model/plot_lasso_coordinate_descent_path.py\n",
      " |      <sphx_glr_auto_examples_linear_model_plot_lasso_coordinate_descent_path.py>`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  sparse_coef_\n",
      " |      Sparse representation of the fitted `coef_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ElasticNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e3337c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_elastic_model = ElasticNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aba1297",
   "metadata": {},
   "source": [
    "# Grid Search \n",
    "**A Grid Search consists of:**  \n",
    "An Estimator    \n",
    "A Parameter space  \n",
    "A method for searching or sampling the data  \n",
    "A cross validation scheme  \n",
    "A score function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c30304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"alpha\":[.1,1,5,10,50,100],\n",
    "            \"l1_ratio\":[.1,.5,.7,.9,.95,.99,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5adc1cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99a693e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = GridSearchCV(estimator = base_elastic_model,\n",
    "                          param_grid = param_grid,\n",
    "                          scoring = \"neg_mean_squared_error\",\n",
    "                          cv = 5,\n",
    "                          verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f94dbc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
      " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
      " |  implemented in the estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list, tuple or dict, default=None\n",
      " |      Strategy to evaluate the performance of the cross-validated model on\n",
      " |      the test set.\n",
      " |  \n",
      " |      If `scoring` represents a single score, one can use:\n",
      " |  \n",
      " |      - a single string (see :ref:`scoring_parameter`);\n",
      " |      - a callable (see :ref:`scoring`) that returns a single value.\n",
      " |  \n",
      " |      If `scoring` represents multiple scores, one can use:\n",
      " |  \n",
      " |      - a list or tuple of unique strings;\n",
      " |      - a callable returning a dictionary where the keys are the metric\n",
      " |        names and the values are the metric scores;\n",
      " |      - a dictionary with metric names as keys and callables a values.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
      " |      with `shuffle=False` so the splits will be the same across calls.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  verbose : int\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |      - >1 : the computation time for each fold and parameter candidate is\n",
      " |        displayed;\n",
      " |      - >2 : the score is also displayed;\n",
      " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
      " |        together with the starting time of the computation.\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default='2*n_jobs'\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  multimetric_ : bool\n",
      " |      Whether or not the scorers compute several metrics.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels. This is present only if ``refit`` is specified and\n",
      " |      the underlying estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `n_features_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `feature_names_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  ---------\n",
      " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
      " |  train_test_split : Utility function to split the data into a development\n",
      " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
      " |      for its final evaluation.\n",
      " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      " |      loss function.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,) or (n_samples, n_classes)                 or (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Result of the decision function for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Instance of fitted estimator.\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Result of the `inverse_transform` function for `Xt` based on the\n",
      " |          estimator with the best found parameters.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          The predicted labels or values for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class log-probabilities for `X` based on the estimator\n",
      " |          with the best found parameters. The order of the classes\n",
      " |          corresponds to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class probabilities for `X` based on the estimator with\n",
      " |          the best found parameters. The order of the classes corresponds\n",
      " |          to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Return the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          The score defined by ``scoring`` if provided, and the\n",
      " |          ``best_estimator_.score`` method otherwise.\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Call score_samples on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``score_samples``.\n",
      " |      \n",
      " |      .. versionadded:: 0.24\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements\n",
      " |          of the underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,)\n",
      " |          The ``best_estimator_.score_samples`` method.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          `X` transformed in the new space based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |      Class labels.\n",
      " |      \n",
      " |      Only available when `refit=True` and the estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |      \n",
      " |      Only available when `refit=True`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3c27fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=0.1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=0.1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=0.1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=1, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=1, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=1, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ..............................alpha=5, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END .............................alpha=5, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ................................alpha=5, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=10, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=10, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=10, l1_ratio=1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END .............................alpha=50, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ............................alpha=50, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ...............................alpha=50, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.1; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.5; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.7; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ............................alpha=100, l1_ratio=0.9; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.95; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ...........................alpha=100, l1_ratio=0.99; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n",
      "[CV] END ..............................alpha=100, l1_ratio=1; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ElasticNet(),\n",
       "             param_grid={'alpha': [0.1, 1, 5, 10, 50, 100],\n",
       "                         'l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]},\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0fec7b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, l1_ratio=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "159adaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.1}</td>\n",
       "      <td>-3.453021</td>\n",
       "      <td>-1.405190</td>\n",
       "      <td>-5.789125</td>\n",
       "      <td>-2.187302</td>\n",
       "      <td>-4.645576</td>\n",
       "      <td>-3.496043</td>\n",
       "      <td>1.591601</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.5}</td>\n",
       "      <td>-3.325440</td>\n",
       "      <td>-1.427522</td>\n",
       "      <td>-5.595610</td>\n",
       "      <td>-2.163089</td>\n",
       "      <td>-4.451679</td>\n",
       "      <td>-3.392668</td>\n",
       "      <td>1.506827</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.7}</td>\n",
       "      <td>-3.269880</td>\n",
       "      <td>-1.442432</td>\n",
       "      <td>-5.502437</td>\n",
       "      <td>-2.163950</td>\n",
       "      <td>-4.356738</td>\n",
       "      <td>-3.347088</td>\n",
       "      <td>1.462765</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.9}</td>\n",
       "      <td>-3.221397</td>\n",
       "      <td>-1.465339</td>\n",
       "      <td>-5.416447</td>\n",
       "      <td>-2.173493</td>\n",
       "      <td>-4.263887</td>\n",
       "      <td>-3.308112</td>\n",
       "      <td>1.417693</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.95}</td>\n",
       "      <td>-3.213052</td>\n",
       "      <td>-1.472417</td>\n",
       "      <td>-5.396258</td>\n",
       "      <td>-2.177452</td>\n",
       "      <td>-4.241080</td>\n",
       "      <td>-3.300052</td>\n",
       "      <td>1.406248</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.99}</td>\n",
       "      <td>-3.208124</td>\n",
       "      <td>-1.478489</td>\n",
       "      <td>-5.380242</td>\n",
       "      <td>-2.181097</td>\n",
       "      <td>-4.222968</td>\n",
       "      <td>-3.294184</td>\n",
       "      <td>1.396953</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 1}</td>\n",
       "      <td>-3.206943</td>\n",
       "      <td>-1.480065</td>\n",
       "      <td>-5.376257</td>\n",
       "      <td>-2.182076</td>\n",
       "      <td>-4.218460</td>\n",
       "      <td>-3.292760</td>\n",
       "      <td>1.394613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.1}</td>\n",
       "      <td>-9.827475</td>\n",
       "      <td>-5.261525</td>\n",
       "      <td>-11.875347</td>\n",
       "      <td>-7.449195</td>\n",
       "      <td>-8.542329</td>\n",
       "      <td>-8.591174</td>\n",
       "      <td>2.222939</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.5}</td>\n",
       "      <td>-8.707071</td>\n",
       "      <td>-4.214228</td>\n",
       "      <td>-10.879261</td>\n",
       "      <td>-6.204545</td>\n",
       "      <td>-7.173031</td>\n",
       "      <td>-7.435627</td>\n",
       "      <td>2.255532</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.7}</td>\n",
       "      <td>-7.920870</td>\n",
       "      <td>-3.549562</td>\n",
       "      <td>-10.024877</td>\n",
       "      <td>-5.379553</td>\n",
       "      <td>-6.324836</td>\n",
       "      <td>-6.639940</td>\n",
       "      <td>2.206213</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.9}</td>\n",
       "      <td>-6.983855</td>\n",
       "      <td>-2.790355</td>\n",
       "      <td>-8.997108</td>\n",
       "      <td>-4.414928</td>\n",
       "      <td>-5.545769</td>\n",
       "      <td>-5.746403</td>\n",
       "      <td>2.128364</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.95}</td>\n",
       "      <td>-6.729435</td>\n",
       "      <td>-2.591285</td>\n",
       "      <td>-8.709842</td>\n",
       "      <td>-4.156317</td>\n",
       "      <td>-5.329916</td>\n",
       "      <td>-5.503359</td>\n",
       "      <td>2.102835</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 0.99}</td>\n",
       "      <td>-6.521344</td>\n",
       "      <td>-2.431385</td>\n",
       "      <td>-8.471086</td>\n",
       "      <td>-3.946327</td>\n",
       "      <td>-5.151344</td>\n",
       "      <td>-5.304297</td>\n",
       "      <td>2.079945</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'l1_ratio': 1}</td>\n",
       "      <td>-6.468807</td>\n",
       "      <td>-2.391483</td>\n",
       "      <td>-8.410171</td>\n",
       "      <td>-3.893566</td>\n",
       "      <td>-5.105922</td>\n",
       "      <td>-5.253990</td>\n",
       "      <td>2.073832</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.1}</td>\n",
       "      <td>-22.979265</td>\n",
       "      <td>-15.547104</td>\n",
       "      <td>-23.668249</td>\n",
       "      <td>-19.921063</td>\n",
       "      <td>-16.262737</td>\n",
       "      <td>-19.675684</td>\n",
       "      <td>3.334901</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.5}</td>\n",
       "      <td>-27.793488</td>\n",
       "      <td>-18.602269</td>\n",
       "      <td>-27.107849</td>\n",
       "      <td>-23.945227</td>\n",
       "      <td>-18.064635</td>\n",
       "      <td>-23.102694</td>\n",
       "      <td>4.108297</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.7}</td>\n",
       "      <td>-29.655510</td>\n",
       "      <td>-21.085059</td>\n",
       "      <td>-29.629478</td>\n",
       "      <td>-26.724595</td>\n",
       "      <td>-20.223654</td>\n",
       "      <td>-25.463659</td>\n",
       "      <td>4.077877</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.9}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.95}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 0.99}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 5, 'l1_ratio': 1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.1}</td>\n",
       "      <td>-27.385346</td>\n",
       "      <td>-19.159534</td>\n",
       "      <td>-27.635464</td>\n",
       "      <td>-24.154104</td>\n",
       "      <td>-18.968161</td>\n",
       "      <td>-23.460522</td>\n",
       "      <td>3.794608</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.5}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.7}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.9}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.95}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 0.99}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 10, 'l1_ratio': 1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.5}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.7}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>50</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.9}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>50</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.95}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>50</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 0.99}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 50, 'l1_ratio': 1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.5}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.7}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.9}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>100</td>\n",
       "      <td>0.95</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.95}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 0.99}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 100, 'l1_ratio': 1}</td>\n",
       "      <td>-31.130307</td>\n",
       "      <td>-22.549433</td>\n",
       "      <td>-31.155204</td>\n",
       "      <td>-27.963447</td>\n",
       "      <td>-21.698192</td>\n",
       "      <td>-26.899317</td>\n",
       "      <td>4.077240</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.001799      0.000747         0.000799        0.000400         0.1   \n",
       "1        0.000801      0.000400         0.000598        0.000488         0.1   \n",
       "2        0.000999      0.000632         0.000401        0.000491         0.1   \n",
       "3        0.000800      0.000400         0.000000        0.000000         0.1   \n",
       "4        0.000600      0.000490         0.000400        0.000490         0.1   \n",
       "5        0.000599      0.000489         0.000400        0.000490         0.1   \n",
       "6        0.001002      0.000004         0.000597        0.000487         0.1   \n",
       "7        0.000600      0.000490         0.000400        0.000490           1   \n",
       "8        0.000600      0.000490         0.000200        0.000400           1   \n",
       "9        0.001000      0.000001         0.000000        0.000000           1   \n",
       "10       0.000800      0.000400         0.000400        0.000490           1   \n",
       "11       0.000600      0.000490         0.000200        0.000400           1   \n",
       "12       0.000800      0.000400         0.000200        0.000399           1   \n",
       "13       0.000600      0.000490         0.000400        0.000490           1   \n",
       "14       0.000799      0.000400         0.000202        0.000403           5   \n",
       "15       0.000601      0.000491         0.000399        0.000488           5   \n",
       "16       0.001001      0.000003         0.000000        0.000000           5   \n",
       "17       0.000400      0.000490         0.000400        0.000490           5   \n",
       "18       0.000800      0.000400         0.000201        0.000403           5   \n",
       "19       0.000600      0.000490         0.000599        0.000489           5   \n",
       "20       0.001197      0.000401         0.000400        0.000490           5   \n",
       "21       0.001399      0.000490         0.000600        0.000490          10   \n",
       "22       0.001200      0.000398         0.000400        0.000490          10   \n",
       "23       0.000999      0.000001         0.000199        0.000398          10   \n",
       "24       0.001402      0.000486         0.000396        0.000485          10   \n",
       "25       0.000800      0.000748         0.000200        0.000399          10   \n",
       "26       0.000798      0.000399         0.000400        0.000489          10   \n",
       "27       0.000602      0.000491         0.000399        0.000489          10   \n",
       "28       0.000602      0.000492         0.000397        0.000487          50   \n",
       "29       0.000600      0.000490         0.000401        0.000492          50   \n",
       "30       0.000600      0.000490         0.000400        0.000490          50   \n",
       "31       0.000799      0.000400         0.000200        0.000400          50   \n",
       "32       0.000800      0.000400         0.000200        0.000400          50   \n",
       "33       0.000800      0.000748         0.000400        0.000490          50   \n",
       "34       0.000400      0.000489         0.000400        0.000490          50   \n",
       "35       0.000802      0.000401         0.000200        0.000399         100   \n",
       "36       0.000799      0.000399         0.000200        0.000400         100   \n",
       "37       0.000998      0.000003         0.000000        0.000000         100   \n",
       "38       0.000600      0.000490         0.000400        0.000490         100   \n",
       "39       0.000600      0.000490         0.000601        0.000490         100   \n",
       "40       0.000600      0.000490         0.000200        0.000400         100   \n",
       "41       0.000800      0.000400         0.000200        0.000400         100   \n",
       "\n",
       "   param_l1_ratio                            params  split0_test_score  \\\n",
       "0             0.1   {'alpha': 0.1, 'l1_ratio': 0.1}          -3.453021   \n",
       "1             0.5   {'alpha': 0.1, 'l1_ratio': 0.5}          -3.325440   \n",
       "2             0.7   {'alpha': 0.1, 'l1_ratio': 0.7}          -3.269880   \n",
       "3             0.9   {'alpha': 0.1, 'l1_ratio': 0.9}          -3.221397   \n",
       "4            0.95  {'alpha': 0.1, 'l1_ratio': 0.95}          -3.213052   \n",
       "5            0.99  {'alpha': 0.1, 'l1_ratio': 0.99}          -3.208124   \n",
       "6               1     {'alpha': 0.1, 'l1_ratio': 1}          -3.206943   \n",
       "7             0.1     {'alpha': 1, 'l1_ratio': 0.1}          -9.827475   \n",
       "8             0.5     {'alpha': 1, 'l1_ratio': 0.5}          -8.707071   \n",
       "9             0.7     {'alpha': 1, 'l1_ratio': 0.7}          -7.920870   \n",
       "10            0.9     {'alpha': 1, 'l1_ratio': 0.9}          -6.983855   \n",
       "11           0.95    {'alpha': 1, 'l1_ratio': 0.95}          -6.729435   \n",
       "12           0.99    {'alpha': 1, 'l1_ratio': 0.99}          -6.521344   \n",
       "13              1       {'alpha': 1, 'l1_ratio': 1}          -6.468807   \n",
       "14            0.1     {'alpha': 5, 'l1_ratio': 0.1}         -22.979265   \n",
       "15            0.5     {'alpha': 5, 'l1_ratio': 0.5}         -27.793488   \n",
       "16            0.7     {'alpha': 5, 'l1_ratio': 0.7}         -29.655510   \n",
       "17            0.9     {'alpha': 5, 'l1_ratio': 0.9}         -31.130307   \n",
       "18           0.95    {'alpha': 5, 'l1_ratio': 0.95}         -31.130307   \n",
       "19           0.99    {'alpha': 5, 'l1_ratio': 0.99}         -31.130307   \n",
       "20              1       {'alpha': 5, 'l1_ratio': 1}         -31.130307   \n",
       "21            0.1    {'alpha': 10, 'l1_ratio': 0.1}         -27.385346   \n",
       "22            0.5    {'alpha': 10, 'l1_ratio': 0.5}         -31.130307   \n",
       "23            0.7    {'alpha': 10, 'l1_ratio': 0.7}         -31.130307   \n",
       "24            0.9    {'alpha': 10, 'l1_ratio': 0.9}         -31.130307   \n",
       "25           0.95   {'alpha': 10, 'l1_ratio': 0.95}         -31.130307   \n",
       "26           0.99   {'alpha': 10, 'l1_ratio': 0.99}         -31.130307   \n",
       "27              1      {'alpha': 10, 'l1_ratio': 1}         -31.130307   \n",
       "28            0.1    {'alpha': 50, 'l1_ratio': 0.1}         -31.130307   \n",
       "29            0.5    {'alpha': 50, 'l1_ratio': 0.5}         -31.130307   \n",
       "30            0.7    {'alpha': 50, 'l1_ratio': 0.7}         -31.130307   \n",
       "31            0.9    {'alpha': 50, 'l1_ratio': 0.9}         -31.130307   \n",
       "32           0.95   {'alpha': 50, 'l1_ratio': 0.95}         -31.130307   \n",
       "33           0.99   {'alpha': 50, 'l1_ratio': 0.99}         -31.130307   \n",
       "34              1      {'alpha': 50, 'l1_ratio': 1}         -31.130307   \n",
       "35            0.1   {'alpha': 100, 'l1_ratio': 0.1}         -31.130307   \n",
       "36            0.5   {'alpha': 100, 'l1_ratio': 0.5}         -31.130307   \n",
       "37            0.7   {'alpha': 100, 'l1_ratio': 0.7}         -31.130307   \n",
       "38            0.9   {'alpha': 100, 'l1_ratio': 0.9}         -31.130307   \n",
       "39           0.95  {'alpha': 100, 'l1_ratio': 0.95}         -31.130307   \n",
       "40           0.99  {'alpha': 100, 'l1_ratio': 0.99}         -31.130307   \n",
       "41              1     {'alpha': 100, 'l1_ratio': 1}         -31.130307   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           -1.405190          -5.789125          -2.187302   \n",
       "1           -1.427522          -5.595610          -2.163089   \n",
       "2           -1.442432          -5.502437          -2.163950   \n",
       "3           -1.465339          -5.416447          -2.173493   \n",
       "4           -1.472417          -5.396258          -2.177452   \n",
       "5           -1.478489          -5.380242          -2.181097   \n",
       "6           -1.480065          -5.376257          -2.182076   \n",
       "7           -5.261525         -11.875347          -7.449195   \n",
       "8           -4.214228         -10.879261          -6.204545   \n",
       "9           -3.549562         -10.024877          -5.379553   \n",
       "10          -2.790355          -8.997108          -4.414928   \n",
       "11          -2.591285          -8.709842          -4.156317   \n",
       "12          -2.431385          -8.471086          -3.946327   \n",
       "13          -2.391483          -8.410171          -3.893566   \n",
       "14         -15.547104         -23.668249         -19.921063   \n",
       "15         -18.602269         -27.107849         -23.945227   \n",
       "16         -21.085059         -29.629478         -26.724595   \n",
       "17         -22.549433         -31.155204         -27.963447   \n",
       "18         -22.549433         -31.155204         -27.963447   \n",
       "19         -22.549433         -31.155204         -27.963447   \n",
       "20         -22.549433         -31.155204         -27.963447   \n",
       "21         -19.159534         -27.635464         -24.154104   \n",
       "22         -22.549433         -31.155204         -27.963447   \n",
       "23         -22.549433         -31.155204         -27.963447   \n",
       "24         -22.549433         -31.155204         -27.963447   \n",
       "25         -22.549433         -31.155204         -27.963447   \n",
       "26         -22.549433         -31.155204         -27.963447   \n",
       "27         -22.549433         -31.155204         -27.963447   \n",
       "28         -22.549433         -31.155204         -27.963447   \n",
       "29         -22.549433         -31.155204         -27.963447   \n",
       "30         -22.549433         -31.155204         -27.963447   \n",
       "31         -22.549433         -31.155204         -27.963447   \n",
       "32         -22.549433         -31.155204         -27.963447   \n",
       "33         -22.549433         -31.155204         -27.963447   \n",
       "34         -22.549433         -31.155204         -27.963447   \n",
       "35         -22.549433         -31.155204         -27.963447   \n",
       "36         -22.549433         -31.155204         -27.963447   \n",
       "37         -22.549433         -31.155204         -27.963447   \n",
       "38         -22.549433         -31.155204         -27.963447   \n",
       "39         -22.549433         -31.155204         -27.963447   \n",
       "40         -22.549433         -31.155204         -27.963447   \n",
       "41         -22.549433         -31.155204         -27.963447   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           -4.645576        -3.496043        1.591601                7  \n",
       "1           -4.451679        -3.392668        1.506827                6  \n",
       "2           -4.356738        -3.347088        1.462765                5  \n",
       "3           -4.263887        -3.308112        1.417693                4  \n",
       "4           -4.241080        -3.300052        1.406248                3  \n",
       "5           -4.222968        -3.294184        1.396953                2  \n",
       "6           -4.218460        -3.292760        1.394613                1  \n",
       "7           -8.542329        -8.591174        2.222939               14  \n",
       "8           -7.173031        -7.435627        2.255532               13  \n",
       "9           -6.324836        -6.639940        2.206213               12  \n",
       "10          -5.545769        -5.746403        2.128364               11  \n",
       "11          -5.329916        -5.503359        2.102835               10  \n",
       "12          -5.151344        -5.304297        2.079945                9  \n",
       "13          -5.105922        -5.253990        2.073832                8  \n",
       "14         -16.262737       -19.675684        3.334901               15  \n",
       "15         -18.064635       -23.102694        4.108297               16  \n",
       "16         -20.223654       -25.463659        4.077877               18  \n",
       "17         -21.698192       -26.899317        4.077240               19  \n",
       "18         -21.698192       -26.899317        4.077240               19  \n",
       "19         -21.698192       -26.899317        4.077240               19  \n",
       "20         -21.698192       -26.899317        4.077240               19  \n",
       "21         -18.968161       -23.460522        3.794608               17  \n",
       "22         -21.698192       -26.899317        4.077240               19  \n",
       "23         -21.698192       -26.899317        4.077240               19  \n",
       "24         -21.698192       -26.899317        4.077240               19  \n",
       "25         -21.698192       -26.899317        4.077240               19  \n",
       "26         -21.698192       -26.899317        4.077240               19  \n",
       "27         -21.698192       -26.899317        4.077240               19  \n",
       "28         -21.698192       -26.899317        4.077240               19  \n",
       "29         -21.698192       -26.899317        4.077240               19  \n",
       "30         -21.698192       -26.899317        4.077240               19  \n",
       "31         -21.698192       -26.899317        4.077240               19  \n",
       "32         -21.698192       -26.899317        4.077240               19  \n",
       "33         -21.698192       -26.899317        4.077240               19  \n",
       "34         -21.698192       -26.899317        4.077240               19  \n",
       "35         -21.698192       -26.899317        4.077240               19  \n",
       "36         -21.698192       -26.899317        4.077240               19  \n",
       "37         -21.698192       -26.899317        4.077240               19  \n",
       "38         -21.698192       -26.899317        4.077240               19  \n",
       "39         -21.698192       -26.899317        4.077240               19  \n",
       "40         -21.698192       -26.899317        4.077240               19  \n",
       "41         -21.698192       -26.899317        4.077240               19  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results...\n",
    "pd.DataFrame(grid_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "55597092",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ba7e6a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133.9751471129042"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c27fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529abcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b63f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
